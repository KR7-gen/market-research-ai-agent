# **要件定義書（V1）**

---

# **要件定義書（V1・最終版）**

## **Deep Research型 市場調査レポート生成ツール（Web \+ YouTube \+ 内部RAG）**

---

## **1\. 目的とゴール**

### **1.1 目的**

ユーザーが入力したテーマに対し、\*\*根拠（Evidence）付きで、読みやすく整理された「Deep Research型レポート」\*\*を自動生成する。

単なる検索まとめではなく、以下の方針を採用する：

* **調査の前に、まず“最終アウトプットの骨格（完成形）”を作る**  
* 骨格に対し「必要な根拠・仮説・反証」を定義し、**それを裏取りする形で調査する**  
* 章単位で「設計→根拠収集→執筆→レビュー」を回し、**途中保存・部分再実行**を可能にする

### **1.2 V1の必達ゴール**

* **市場調査レポート**を高品質に出せる（最優先）  
* 市場調査以外の「調べてほしい」系も、汎用的に対応できる（UI分岐を増やさない）  
* **根拠ソースとして Web \+ YouTube字幕（トランスクリプト） \+ 内部RAG（PDF/テキスト）をV1から利用可能**  
* 失敗しても **完了した章は保存**され、**失敗章だけ再実行**できる  
* 各主張に出典が紐付き、**どの根拠で書いたか追跡できる**

---

## **2\. 利用者・ユースケース**

### **2.1 想定ユーザー**

* 事業開発、マーケ、営業企画、経営層、起業家  
* 例：  
  * 「◯◯市場の規模・成長率・競合・参入障壁を知りたい」  
  * 「このビジネスで3年以内に年商1億は現実的か？」

### **2.2 ユーザーが得る価値**

* 意思決定に必要な情報が、**章立てされたレポート**としてまとまる  
* 根拠が見える（URL / YouTube動画 / 内部資料）ため、**検証・共有に耐える**

---

## **3\. 重要方針（品質の再現性を作る設計）**

### **方針A：検索の前に“完成形（骨格）”を作る**

いきなり検索せず、最初にLLMで「完成イメージ」を作る。

これにより、情報が散らばった“寄せ集め”レポートを防ぐ。

### **方針B：章単位で処理し、途中保存・部分再実行を可能にする**

レポート生成は長時間になり失敗しやすい。

よって、章単位で保存し、失敗章のみ再実行できる構造にする。

### **方針C：レビューは「機械チェック \+ LLMレビュー」のハイブリッド**

* ルールで判定できるもの（引用数不足、断定語、数字根拠不足等）は機械でチェック

* 論理・抜け漏れ・整合性はLLMで章単位レビュー

   全文丸投げレビューは避け、**章単位＋章サマリ**で扱う。

### **方針D：根拠ソースを“最初から”多元化する**

V1から以下を根拠として扱う：

* Web（検索＋本文）  
* YouTube（検索＋字幕）  
* 内部ナレ（管理画面投入PDF/テキスト → RAG検索）

ユーザーは「優先順」を指定できる（例：内部→YouTube→Web）。

---

## **4\. 機能要件**

### **4.1 ユーザー機能**

### **4.1.1 レポート作成**

* 入力（必須）：自由テキスト  
* 入力（任意）：目的、前提、対象地域、期間、重視観点  
* 入力（任意）：根拠ソース優先順  
  * 例：内部資料優先 / YouTube優先 / Web優先 / すべて同等

### **4.1.2 進捗表示（章単位）**

* 章ごとの状態を表示：  
  * 設計中（骨格）  
  * 根拠収集中（Web / YouTube / 内部）  
  * 執筆中  
  * レビュー中  
  * 完了  
  * 失敗（再実行可能）

### **4.1.3 完成レポート閲覧**

* 章立て表示  
* 各章に引用（根拠）リンクが付く  
* ソース一覧（Web URL / YouTube動画 / 内部資料）を付与

### **4.1.4 失敗章の再実行**

* 「この章だけ再生成」「全体再生成」「スキップして続行」を提供

---

### **4.2 管理機能（V1から必須：RAG運用）**

### **4.2.1 内部資料の投入（RAG）**

* 管理画面から以下をアップロード可能：  
  * PDF（テキスト抽出できるものをV1対象）  
  * テキスト（メモ、ガイドライン、業界指標集など）  
* 投入資料は「カテゴリ」「タグ」「適用範囲（全レポート/特定テーマのみ）」を設定可能

### **4.2.2 内部ポリシー（調査の基本ルール）管理**

* 調査テンプレ（章構成の雛形）  
* 必須観点（市場調査で必ず見る項目など）  
* 品質ルール（最低引用数、一次情報優先など）  
* よく使う指標（TAM/SAM/SOM、CAGR等）を運営が定義できる

目的：運営が「良いレポートの型」を積み上げ、生成品質を継続的に上げられるようにする。

---

## **5\. レポート生成フロー（改善版：具体手順）**

ここが本プロダクトの中核です。**必ずこの順番**で動く。

---

### **Phase 0：ジョブ受付**

1. ユーザーがテーマを入力し「生成」  
2. システムはジョブを作成し、裏側のワーカーへ依頼  
3. 進捗画面を表示

---

### **Phase 1：完成形（骨格）生成（検索しない）**

1. 目的の分類（内部的に判定、ユーザーに強制しない）  
2. LLMで「仮の完成レポート」を作成：  
* 章立て  
* 各章の“暫定結論（仮説）”  
* 各章で必要な根拠タイプ（統計、企業IR、専門家、動画等）  
* 必須の数字（市場規模、成長率、競合数など）

ここで“型”を作ることで、後から情報が増えてもレポートが散らからない。

---

### **Phase 2：章ごとの調査設計（Evidence Plan）**

各章ごとに以下を決める：

* 主仮説（H）と反証仮説（Anti-H）  
* 必要根拠条件（例）：  
  * 根拠3件以上  
  * 一次情報1件以上  
  * 数値根拠1件以上  
* 検索クエリセットを作る（章ごと）：  
  * 広く（概観）  
  * 深く（一次情報）  
  * 反証（否定・異論）  
  * 最新（直近動向）  
  * 日本（必要なら）

さらに、ここで **根拠ソースの優先順（内部/YouTube/Web）** を反映する。

---

### **Phase 3：根拠収集（内部RAG → YouTube → Web の順で“必要なだけ”）**

章単位で、足りるまで集める。足りなければ追加検索する。

### **3-A 内部RAG（管理画面投入資料の検索）**

* 章の論点に関連する内部資料を検索し、候補テキストをEvidenceとして保存  
* 内部資料は「信頼度が高い根拠」として優先引用されやすい

### **3-B YouTube（検索 → 字幕取得 → Evidence化）**

* YouTube動画を検索し候補を取得（公式のYouTube Data API v3） ([Google for Developers](https://developers.google.com/youtube/v3/guides/quota_and_compliance_audits?utm_source=chatgpt.com))  
* 字幕（トランスクリプト）を取得し、Evidenceとして保存  
  * 公式APIの字幕ダウンロード（captions.download）はOAuthスコープ等が必要で、権限の壁が出やすい ([Google for Developers](https://developers.google.com/youtube/v3/docs/captions/download?hl=ja&utm_source=chatgpt.com))  
  * V1は **公開トランスクリプト取得のライブラリ**を利用する（例：Nodeで字幕取得可能な `youtube-transcript`） ([npm](https://www.npmjs.com/package/youtube-transcript?utm_source=chatgpt.com))  
  * 注意：非公式取得は仕様変更で動かなくなる可能性があるため、フォールバック戦略を用意（後述）

### **3-C Web（検索 → 本文抽出 → Evidence化）**

* Tavilyで検索し、URL候補→本文抽出→Evidence保存  
* 本文が薄い/抽出失敗時は、Readabilityで本文抽出して補完（フォールバック）

---

### **Phase 4：章の執筆（引用必須・テンプレ固定）**

章ごとに、集めたEvidenceを使って執筆する。

章テンプレ（固定）：

1. 結論（1〜3行）  
2. 根拠（引用付き：Web/YouTube/内部）  
3. 解釈（なぜそう言えるか）  
4. 反証・リスク（反対情報も書く）  
5. 次のアクション（意思決定に必要な示唆）

このテンプレ固定が、品質のばらつきを抑える。

章が完成したら即保存（途中保存の要）。

---

### **Phase 5：章レビュー（機械チェック → LLMレビュー）**

### **5-A 機械チェック（ルール）**

例：

* 引用数が最低条件を満たすか  
* “断定語”が引用なしで出ていないか  
* 数字があるなら出典が紐づいているか  
* 同一ドメイン/同一動画への偏りが強すぎないか

NGなら：

* 根拠追加（Phase 3へ戻る）  
* または章再執筆（Phase 4へ戻る）

### **5-B LLMレビュー（章単位）**

* 章本文 \+ Evidenceサマリのみを渡してレビュー  
* 出力：改善点、追加調査指示、文章修正案  
* 必要なら差分修正（再執筆）

---

### **Phase 6：全体統合（レポート完成）**

* 章間の矛盾チェック（定義・期間・地域のズレ）  
* 全体サマリ（エグゼクティブサマリ）生成  
* ソース一覧生成（Web/YouTube/内部資料）

---

## **6\. 非機能要件（性能・安定性）**

### **6.1 レポート生成時間**

* 目標：10〜15分  
* 最大：30分（超過は中断し、途中結果を提示）

### **6.2 同時生成制限**

* 1ユーザーあたり：  
  * Free：1件  
  * Standard：2件  
  * Pro：5件  
* システム全体（初期）：同時50件、待ち100件

### **6.3 障害時**

* 完了章は必ず保存  
* 失敗章だけ再実行  
* 自動リトライ：最大3回（間隔を空ける）

---

## **7\. 採用技術（何に使うか：初心者向け）**

* **Next.js \+ TypeScript**：画面（入力/進捗/レポート表示）とAPI受付  
* **PostgreSQL**：レポート・章・Evidence・引用・管理設定の保存  
* **Redis \+ BullMQ**：長時間ジョブの待ち行列、進捗、同時実行制御  
* **pgvector**：内部資料の“意味検索”（RAG）をDB内で実現  
* **LangChain（TS）**：LLM処理（骨格生成、章執筆、レビュー）を部品化し運用しやすくする  
* **Tavily API**：Web検索＋本文抽出（根拠収集）  
* **Readability**：Web本文抽出のフォールバック（薄い時の補完）  
* **YouTube Data API v3**：YouTube動画検索（公式、クォータ制限あり） ([Google for Developers](https://developers.google.com/youtube/v3/guides/quota_and_compliance_audits?utm_source=chatgpt.com))  
* **YouTube字幕取得ライブラリ（例：youtube-transcript）**：公開トランスクリプト取得（V1現実解、非公式ゆえ変更リスクあり） ([npm](https://www.npmjs.com/package/youtube-transcript?utm_source=chatgpt.com))  
* **OpenTelemetry**：処理の遅延・失敗原因を可視化し運用改善

---

## **8\. YouTubeトランスクリプトのリスクとV1の扱い（必ず仕様化）**

### **8.1 リスク**

* 非公式取得は、YouTube側の変更で動かなくなる可能性がある ([npm](https://www.npmjs.com/package/youtube-transcript?utm_source=chatgpt.com))  
* 公式字幕DL APIはOAuth等の制約が強く、一般動画では運用が難しい場合がある ([Google for Developers](https://developers.google.com/youtube/v3/docs/captions/download?hl=ja&utm_source=chatgpt.com))

### **8.2 V1の対策（仕様）**

* 字幕取得失敗時は次を実行：  
  1. その動画はEvidence候補から除外  
  2. 代替動画を追加探索  
  3. どうしても必要ならWeb根拠で補強  
* 管理画面に「YouTube字幕取得失敗率」「失敗理由」を表示（運用改善）

---

## **9\. RAG（内部資料）V1仕様の前提**

* V1はまず「**テキスト抽出できるPDF**」を対象とする  
* スキャンPDF等のOCRは将来拡張（V1スコープ外だが設計余地は残す）  
* 内部資料は“信頼度が高い根拠”として優先されやすい（ただし、必ず引用表示する）

---

## **10\. 受け入れ基準（完成判定）**

* V1で **Web/YouTube/内部RAG** の根拠がいずれも利用できる  
* 各章に最低限の根拠が紐づく（引用ゼロ断定がない）  
* 章単位で途中保存・失敗章のみ再実行ができる  
* 30分タイムアウト時に途中結果を提示できる  
* 管理画面から内部資料投入→新規レポートで参照される

---

必要であれば、次のステップとしてこの要件定義書をそのまま実装に落とすために、

1. 画面一覧（UIワイヤーフレームレベル）

2. DBに保存するデータ項目一覧（非エンジニアでも読める形）

3. “章テンプレ”と“機械チェックルール”の初期値

    をセットで提示します。

## **画面**

---

# **1\) 画面一覧（UIワイヤー相当：何が表示され、何ができるか）**

## **1\. ユーザー画面**

### **U1. ログイン／サインアップ（最小）**

* 入力：メール、パスワード（またはSSOは将来）  
* 出力：認証完了 → U2へ

### **U2. レポート一覧（ホーム）**

* 表示  
  * レポートタイトル  
  * 作成日時  
  * ステータス（待機／実行中／完了／失敗）  
  * 根拠ソース構成（例：内部/YouTube/Web）  
* 操作  
  * 「新規作成」→ U3  
  * レポート選択 → U4  
  * 失敗レポートは「再開」→ U4（失敗章が見える）

### **U3. 新規レポート作成（入力フォーム）**

* 入力（必須）  
  * テーマ（自由入力）：例「◯◯市場調査。3年で年商1億は現実的か？」  
* 入力（任意：精度向上）  
  * 目的（選択＋自由追記）：例「参入判断」「投資判断」「競合比較」  
  * 対象地域（日本/海外/任意）  
  * 期間（例：直近3年、将来5年）  
  * 前提条件（例：価格帯、販売チャネル）  
  * 重視観点（チェック）：市場規模/成長率/競合/参入障壁/価格/顧客/規制…  
* 根拠ソース優先順（必須に近い推奨）  
  * 例：①内部資料 ②YouTube ③Web（ドラッグで順序変更）  
  * 「不足時は自動で次ソースへフォールバック」ON（デフォルトON）  
* 実行  
  * 「生成開始」ボタン  
* 生成開始後  
  * U4（進捗）へ遷移

### **U4. 進捗（章単位のステータス一覧）**

* 上部：全体進捗  
  * 推定残り時間（概算）  
  * 現在フェーズ（骨格→根拠→執筆→レビュー→統合）  
* 中央：章リスト（各章カード）  
  * 章タイトル  
  * 状態：設計中／根拠収集中／執筆中／レビュー中／完了／失敗／根拠不足  
  * 根拠数（内部/YouTube/Webの内訳）  
* 下部：ログ（ユーザー向けに翻訳した表示）  
  * 例「YouTube字幕取得に失敗 → 別動画を探索中」  
* 操作  
  * 失敗章：  
    * 「この章だけ再生成」  
    * 「根拠だけ追加」  
    * 「スキップして次へ」（V1では非推奨だが選択肢）  
  * 全体：  
    * 「全体を再生成」  
    * 「中断」（実行停止。途中成果は保持）

### **U5. レポート閲覧（完成版）**

* 表示  
  * エグゼクティブサマリ  
  * 章立て（目次）  
  * 各章本文（テンプレ構造で読みやすく）  
  * 引用（クリックで根拠へ）  
* 根拠パネル（右側/下部）  
  * Web：URL、取得日時  
  * YouTube：動画URL、チャンネル、字幕抜粋  
  * 内部：資料名、該当箇所抜粋  
* 操作  
  * 「章だけ再生成」（改善したい章を指定）  
  * 「根拠追加して再生成」（その章だけ追加調査）  
  * 「エクスポート」（PDF/Markdownは将来でも可。V1はHTMLでOK）

---

## **2\. 管理画面（運営・内部スタッフ用）※V1必須**

### **A1. 管理ダッシュボード**

* 表示  
  * 本日の生成数、失敗率  
  * 平均生成時間  
  * ソース別の失敗（YouTube字幕失敗率、Web抽出失敗率）  
* 操作  
  * 問題の多いジョブ一覧へ遷移

### **A2. 内部資料（RAG）管理：アップロード＆一覧**

* 操作  
  * PDF/テキストアップロード  
  * カテゴリ（例：市場指標、会計指標、業界別KPI、社内ポリシー）  
  * タグ（例：SaaS、飲食、D2C、物流、医療）  
  * 適用範囲（全レポート／特定条件）  
* 表示  
  * 資料一覧、更新日時、利用回数（何回引用されたか）

### **A3. テンプレ管理（章立て・観点）**

* 例：市場調査テンプレ（標準8章）を編集できる  
* 章ごとの「必須観点」「必須指標」「推奨ソース」を定義

### **A4. 品質ルール管理（機械チェック設定）**

* 最低引用数、一次情報の定義、断定語ルールなどのしきい値を調整

### **A5. ジョブ監視（運用）**

* ジョブ一覧（進行中/失敗/タイムアウト）  
* 失敗理由（API rate limit、字幕取得失敗など）  
* 再実行ボタン（運営側からも可能）

---

# **2\) DBに保存するデータ項目一覧（初心者向け：何を保存して何に使うか）**

「表（テーブル）」＝“種類別の保管箱”だと思ってください。

## **2.1 ユーザー・課金系**

### **users（ユーザー）**

* user\_id：ユーザー識別子  
* email：メール  
* plan：Free/Standard/Pro  
* created\_at：登録日時

### **usage\_limits（利用制限：プラン設定）**

* plan：プラン名  
* max\_concurrent\_jobs：同時生成数  
* max\_queue\_jobs：待ち上限（必要なら）

---

## **2.2 レポート本体**

### **reports（レポート）**

* report\_id：レポートID  
* user\_id：作成者  
* title：タイトル（生成時に決める）  
* status：queued/running/completed/failed/cancelled  
* source\_priority：内部→YouTube→Web などの順序  
* started\_at / finished\_at：開始・終了  
* final\_summary：最終サマリ（完成時）  
* final\_content：最終本文（完成時）

### **report\_inputs（入力内容：後で検証できるように保持）**

* report\_id  
* theme\_text：自由入力（必須）  
* purpose\_text：目的（任意）  
* region：地域（任意）  
* period：期間（任意）  
* assumptions：前提（任意）  
* focus\_points：重視観点（任意）

---

## **2.3 章（セクション）管理：途中保存と再実行の核**

### **sections（章）**

* section\_id  
* report\_id  
* order\_no：並び順  
* title：章タイトル  
* status：planned/collecting/drafting/reviewing/completed/failed/needs\_more\_evidence  
* hypothesis\_draft：仮説（調査前）  
* hypothesis\_final：最終結論（調査後）  
* requirements\_json：この章の品質条件（最低根拠数など）  
* content：章本文（完成時）

### **section\_queries（章ごとの検索クエリ）**

* section\_id  
* query\_type：broad/deep/counter/fresh/japan など  
* query\_text：検索文

---

## **2.4 根拠（Evidence）と引用（Citation）：信頼性の核**

### **evidences（根拠アイテム）**

* evidence\_id  
* section\_id  
* source\_type：internal / youtube / web  
* title：根拠タイトル（記事名、動画名、資料名）  
* url：Web/YouTubeの場合  
* fetched\_at：取得日時  
* raw\_text：本文（記事本文、字幕テキスト、内部資料抜粋）  
* summary\_text：要点サマリ（LLMで短くしたもの）  
* credibility\_label：信頼度ラベル（公的/企業/ニュース/ブログ/個人など）  
* fetch\_method：tavily / readability / youtube\_transcript / internal\_chunk  
* meta\_json：再生数、チャンネル名、年度など補助情報

### **citations（引用：本文のどこがどの根拠か）**

* citation\_id  
* section\_id  
* evidence\_id  
* quote\_text：引用・要約（短い）  
* used\_in\_paragraph\_no：章内のどこで使ったか（番号でOK）

---

## **2.5 内部RAG（管理画面投入）**

### **admin\_documents（内部資料）**

* document\_id  
* title：資料名  
* type：pdf / text  
* category：カテゴリ  
* tags：タグ  
* status：active/inactive  
* uploaded\_at

### **admin\_document\_chunks（資料を小分けにした断片：検索しやすくする）**

* chunk\_id  
* document\_id  
* chunk\_text：小分けテキスト  
* embedding\_vector：意味検索用（pgvector）  
* meta\_json：ページ番号など

重要：RAGは「資料を小分けにして、意味で探せるようにする」が基本です。

---

## **2.6 ジョブ運用（非同期処理）**

### **jobs（ジョブ）**

* job\_id  
* report\_id  
* status：queued/running/failed/completed  
* attempts：再試行回数  
* timeout\_at：タイムアウト時刻

### **job\_events（進捗ログ：ユーザーにも出す）**

* job\_id  
* event\_time  
* event\_type：phase\_change / error / retry / info  
* message\_user：ユーザー向けメッセージ  
* message\_internal：内部向け詳細（任意）

---

# **3\) 章テンプレと機械チェック初期値（V1で固定してよい“型”）**

## **3.1 標準アウトライン（市場調査：まずはこの8章を基本）**

V1は迷いを減らすため、デフォルトは固定が推奨です。

1. 概要（結論サマリ）  
2. 市場定義（対象範囲・前提）  
3. 市場規模（TAM/SAM/SOMの考え方含む）  
4. 成長性（CAGR、ドライバー）  
5. 顧客・ユースケース（誰が何のために買うか）  
6. 競合環境（主要プレイヤー、代替、差別化軸）  
7. 参入障壁・リスク（規制、供給、技術、集客、収益性）  
8. 戦略提案（次の一手、検証プラン、年商1億の現実性もここに統合）

「年商1億は現実的か？」のような問いでも、上記8章で自然に回答できます（UIを分けない方針と整合）。

---

## **3.2 章本文テンプレ（各章の文章構造：これを全章に適用）**

各章は必ず同じ型にします。

1. **結論（1〜3行）**  
2. **根拠（引用付き）**  
   * Web / YouTube / 内部資料 のいずれか（複数推奨）  
3. **解釈（なぜそう言えるか）**  
4. **反証・注意点（異論や限界）**  
5. **次アクション（意思決定のための提案）**

---

## **3.3 章ごとの「必要根拠条件」初期値（V1）**

### **最低条件（まずはこれで十分強い）**

* 根拠（Evidence）合計：**最低3件 / 章**  
* うち **一次情報相当：最低1件 / 章**  
  * 例：公的統計、企業IR、調査会社レポートの要約、一次データに近いもの  
* **数値根拠：最低1つ / 章**（可能なら）  
  * 市場規模、成長率、価格帯、ユーザー数、競合数など  
* 新しさ：**原則2年以内を優先**（難しければ「古い可能性」を注記）

### **ソース優先順の扱い**

* ユーザー指定の順で集める  
* 足りない場合のみ次ソースへフォールバック（デフォルトON）

---

## **3.4 機械チェック（ルール判定）初期値：V1の運用品質を決める**

以下は「LLMに頼らず機械で検知できる」ため、最初から入れて損がありません。

### **チェック1：引用数不足**

* 条件：`citations_count < 3`（章）  
* 対応：Phase3へ戻り根拠追加 → 章再生成

### **チェック2：引用なし断定の検知（簡易）**

* 対象語（例）：

   「必ず」「確実」「間違いない」「〜である（強い断定）」「最大」「唯一」など

* 条件：断定語を含む段落に citation が紐付かない

* 対応：該当段落を「要根拠」扱い → 根拠追加 or 表現を弱めて再生成

### **チェック3：数値があるのに出典がない**

* 条件：数字（正規表現で検知）がある段落に citation がない  
* 対応：根拠追加 or 数値表現の削除/弱化

### **チェック4：同一ドメイン偏り（Web）**

* 条件：Web根拠のうち同一ドメイン比率 \> 60%  
* 対応：別ドメインを追加検索

### **チェック5：YouTube字幕が短すぎる／欠落**

* 条件：字幕テキストが極端に短い（例：500文字未満）または取得失敗  
* 対応：別動画を探索 → それでも無理ならWeb/内部で補強

### **チェック6：内部資料の参照不足（ユーザーが内部最優先を指定した場合）**

* 条件：source\_priority が internal最優先なのに internal根拠0  
* 対応：内部RAG検索条件を緩める（関連度しきい値を下げる）→ 再収集

---

## **3.5 LLMレビュー（章単位）の入出力仕様（V1の最小形）**

全文を渡さず、章単位で次の材料だけを渡します。

**入力（LLMへ）**

* 章本文  
* 章の要点サマリ（あなた側で短くしたもの）  
* 根拠サマリ（各Evidenceの要点だけ。本文全部は渡さない）  
* 品質条件（引用数など）

**出力（LLMから）**

* `issues`: 問題点の箇条書き  
* `missing_evidence`: 追加すべき根拠の種類（例：統計が足りない、反証がない）  
* `rewrite_suggestions`: 直すべき文章（該当箇所）  
* `action`: 「追加検索」or「書き直し」or「OK」

---

# **次にこちらから提案（実装を最短にする順番）**

ここまでを踏まえると、開発順は以下が最短です。

1. DBスキーマ（reports/sections/evidences/citations/admin\_documents/admin\_document\_chunks/jobs）  
2. BullMQ \+ Workerで「章単位の状態遷移」を作る（骨格→根拠→章保存まで）  
3. 内部RAG（アップロード→分割→意味検索→Evidence化）  
4. YouTube（検索→字幕→Evidence化）  
5. Web（Tavily→薄い時Readability）  
6. 機械チェック＋LLM章レビュー  
7. 管理画面（テンプレ・ルール・資料）

